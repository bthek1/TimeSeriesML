{"title":"Darts - Hyper-parameters Optimization for Electricity Load Forecasting","markdown":{"yaml":{"description":"[In this notebook, we demonstrate how to carry out hyperparameter optimization using a deep learning forecasting model in order to accurately forecast electricity loads with confidence intervals.](https://unit8co.github.io/darts/examples/17-hyperparameter-optimization.html)","output-file":"hyperparameter optimization.html","title":"Darts - Hyper-parameters Optimization for Electricity Load Forecasting"},"headingText":"Data Preparation","containsRefs":false,"markdown":"\n\n\n\n<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->\n\n\nThe following cell can take a few minutes to execute. It'll download about 250 MB of data from the Internet. We specify `multivariate=False`, so we get a list of 370 *univariate* `TimeSeries`. We could also have specified `multivariate=True` to obtain one *multivariate* `TimeSeries` containing 370 components.\n\nWe keep the last 80 days for each series, and cast all of them to float32:\n\nWe have 370 univariate `TimeSeries`, each with a frequency of 15 minutes. In what follows, we will be training a single global model on all of them.\n\nFirst, we create our training set. We set aside the last 14 days as test set, and the 14 days before that as validation set (which will be used for hyperparameter optimization).\n\nNote that the `val` and `test` sets below only contain the 14-days \"forecast evaluation\" parts of the series. Throughout the notebook, we'll evaluate how accurate some 14-days forecasts are over `val` (or `test`). However, to produce these 14-days forecasts, our models will consume a certain lookback window `in_len` worth of time stamps. For this reason, below we will also create validation sets that include these extra `in_len` points (as `in_len` is a hyper-parameter itself, we create these longer validation sets dynamically); it will be mainly useful for early-stopping.\n\nLet's plot a few of our series:\n\n## Build a Simple Linear Model\n\nWe start off without any hyperparameter optimization, and try a simple linear regression model first. It will serve as a baseline. In this model, we use a lookback window of 1 week.\n\n**Note:** doing significantly better than linear regression is often not trivial! We recommend to always consider at least one such reasonably simple baseline first, before jumping to more complex models.\n\n`LinearRegressionModel` wraps around `sklearn.linear_model.LinearRegression`, which may take a significant amount of processing and memory. Running this cell takes a couple of minutes, and we recommend skipping it unless you have at least 20GB of RAM on your system.\n\nLet's see how this model is doing:\n\nlr_preds = lr_model.predict(series=train, n=val_len)\neval_model(lr_preds, \"linear regression\")\n\nThis model is already doing quite well out of the box! Let's see now if we can do better using deep learning.\n\n## Build a Simple TCN Model\nWe now build a [TCN model](https://unit8co.github.io/darts/generated_api/darts.models.forecasting.tcn_model.html) with some simple choice of hyperparameters, but without any hyperparameter optimization.\n\nAbove, we built a first TCN model without any hyper-parameter search, and got an sMAPE of about 17%. Although this model looks like a good start (performing quite well on some of the series), it's not as good as the simple linear regression.\n\nWe can certainly do better, because there are many parameters that we have fixed but could have a large impact on performance, such as:\n\n* The architecture of the network (number of filters, dilation size, kernel size, etc...)\n* The learning rate\n* Whether to use weight normalization and/or the dropout rate\n* The length of the lookback and lookforward windows\n* Whether to add calendar covariates, such as day-of-the-week\n* ...\n\n\n### One Option: using `gridsearch()`\n\nOne way to try and optimize these hyper-parameters is to try all combinations (assuming we have discretized our parameters). Darts offers a `gridsearch()` method to do just that. The advantage is that it is very simple to use. However, it also has severe drawbacks:\n\n* It takes exponential time in the number of hyper-parameters: grid-searching over any non-trivial number of hyperparameters thus quickly becomes intractable.\n* Gridsearch is naive: it does not attempt to pay attention to regions of the hyperparameter space that are more promising than others. It is limited points in the pre-defined grid.\n* Finally, for simplicity reasons the Darts `gridsearch()` method is (at least at the time of writing) limited to working on one time series only.\n\nFor all these reasons, for any serious hyperparameter search, we need better techniques than grid-search. Fortunately, there are some great tools out there to help us.\n\n## Using Optuna\n\n[Optuna](https://optuna.org/) is a very nice open-source library for hyperparameter optimization. It's based on ideas such as Bayesian optimization, which balance exploration (of the hyperparameter space) with exploitation (namely, exploring more the parts of the space that look more promising). It can also use pruning in order to stop unpromising experiments early.\n\nIt's very easy to make it work: Optuna will take care of suggesting (sampling) hyper-parameters for us, and more or less all we need to do is to compute the objective value for a set of hyperparameters. In our case it consists in using these hyperparameters to build a model, train it, and report the obtained validation accuracy. We also setup a PyTorch Lightning pruning callback in order to early-stop unpromising experiments. All of this is done in the `objective()` function below.\n\nNow that we have specified our objective, all we need to do is create an Optuna study, and run the optimization. We can either ask Optuna to run for a specified period of time (as we do here), or a certain number of trials. Let's run the optimization for a couple of hours:\n\nNote: If we wanted to optimize further, we could still call `study.optimize()` more times to resume where we left off\n\nThere's a lot more that you can do with Optuna. We refer to [the documentation](https://optuna.readthedocs.io/en/stable/index.html) for more information. For instance, it's possible to obtain useful insights into the optimization process, by visualising the objective value history (over trials), the objective value as a function of some of the hyperparameters, or the overall importance of some of the hyperparameters. \n\n## Picking up the best model\n\nAfter running the hyperparameter optimization for a couple of hours on a GPU, we got:\n\n```\nBest value: 14.720555851487694, Best params: {'days_in': 14, 'days_out': 6, 'kernel_size': 19, 'num_filters': 19, 'weight_norm': True, 'dilation_base': 4, 'dropout': 0.07718156729165897, 'lr': 0.0008841998396117885, 'dayofweek': False}\n```\n\nWe can now take these hyperparameters and train the \"best\" model again. This time, we will directly try to fit a probabilistic model (using a Gaussian likelihood). Note that this actually changes the loss, so we're hoping that our hyperparameters are not too sensitive in that regard.\n\nLet's now look at the accuracy of stochastic forecasts, with 100 samples:\n\nThe accuracy seems really good, and this model does not suffer from some of the same issues that our initial linear regression and early TCN had (look for instance in the failure modes it used to have on series 150). \n\nLet's now also see how it performs on the test set:\n\nThe performance is not as good on the test set, but on closer inspection this seems to be due to the Christmas time, during which some of the clients (unsurprisingly) changed their consumption. Besides the Christmas time, the quality of the forecasts seems roughly on par with what we had during the validation set, which is a good indication that we probably did not overfit our hyperparameter optimization to the validation set.\n\nTo improve this model further, it might be a good idea to consider using indicator variables capturing public holidays (which we haven't done here).\n\nAs a last experiment, let's see how our linear regression model performs on the test set:\n\n## Conclusions\n\nWe have seen in this notebook that Optuna can be seamlessly used to optimize the hyper-parameters of Darts' models. In fact, there's nothing really particular to Darts when it comes to hyperparameter optimization: Optuna and other libraries can be used as they would with other frameworks. The only thing to be aware of are the PyTorch Ligthning integrations, which are available through Darts.\n\n### Side conclusion: shall we go with linear regression or TCN to forecast electricty consumption?\n\nBoth approaches have pros and cons.\n\n**Pros of linear regression:**\n\n* Simplicity\n* Does not require scaling\n* Speed\n* Does not require a GPU\n* Often provides good performance out-of-the-box, without requiring tuning\n\n**Cons of linear regression:**\n\n* Can require a significant amount of memory (when used as a global model as here), although there are ways around that (e.g., SGD-based).\n* In our setting, it's impractical to train a stochastic version of the `LinearRegression` model, as this would incur too large a computational complexity.\n\n**TCN, pros:**\n\n* Potentially more tuneable and powerful\n* Typically lower memory requirements thanks to SGD\n* Very rich support to capture stochasticity in different ways, without requiring significantly more computation\n* Very fast bulk inference over many time series once the model is trained - especially if using a GPU\n\n**TCN, cons:**\n\n* More hyperparameters, which can take longer to tune and offer more risks of overfitting. It also means that the model is harder to industrialize and maintain\n* Will often require a GPU\n","srcMarkdownNoYaml":"\n\n\n\n<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->\n\n## Data Preparation\n\nThe following cell can take a few minutes to execute. It'll download about 250 MB of data from the Internet. We specify `multivariate=False`, so we get a list of 370 *univariate* `TimeSeries`. We could also have specified `multivariate=True` to obtain one *multivariate* `TimeSeries` containing 370 components.\n\nWe keep the last 80 days for each series, and cast all of them to float32:\n\nWe have 370 univariate `TimeSeries`, each with a frequency of 15 minutes. In what follows, we will be training a single global model on all of them.\n\nFirst, we create our training set. We set aside the last 14 days as test set, and the 14 days before that as validation set (which will be used for hyperparameter optimization).\n\nNote that the `val` and `test` sets below only contain the 14-days \"forecast evaluation\" parts of the series. Throughout the notebook, we'll evaluate how accurate some 14-days forecasts are over `val` (or `test`). However, to produce these 14-days forecasts, our models will consume a certain lookback window `in_len` worth of time stamps. For this reason, below we will also create validation sets that include these extra `in_len` points (as `in_len` is a hyper-parameter itself, we create these longer validation sets dynamically); it will be mainly useful for early-stopping.\n\nLet's plot a few of our series:\n\n## Build a Simple Linear Model\n\nWe start off without any hyperparameter optimization, and try a simple linear regression model first. It will serve as a baseline. In this model, we use a lookback window of 1 week.\n\n**Note:** doing significantly better than linear regression is often not trivial! We recommend to always consider at least one such reasonably simple baseline first, before jumping to more complex models.\n\n`LinearRegressionModel` wraps around `sklearn.linear_model.LinearRegression`, which may take a significant amount of processing and memory. Running this cell takes a couple of minutes, and we recommend skipping it unless you have at least 20GB of RAM on your system.\n\nLet's see how this model is doing:\n\nlr_preds = lr_model.predict(series=train, n=val_len)\neval_model(lr_preds, \"linear regression\")\n\nThis model is already doing quite well out of the box! Let's see now if we can do better using deep learning.\n\n## Build a Simple TCN Model\nWe now build a [TCN model](https://unit8co.github.io/darts/generated_api/darts.models.forecasting.tcn_model.html) with some simple choice of hyperparameters, but without any hyperparameter optimization.\n\nAbove, we built a first TCN model without any hyper-parameter search, and got an sMAPE of about 17%. Although this model looks like a good start (performing quite well on some of the series), it's not as good as the simple linear regression.\n\nWe can certainly do better, because there are many parameters that we have fixed but could have a large impact on performance, such as:\n\n* The architecture of the network (number of filters, dilation size, kernel size, etc...)\n* The learning rate\n* Whether to use weight normalization and/or the dropout rate\n* The length of the lookback and lookforward windows\n* Whether to add calendar covariates, such as day-of-the-week\n* ...\n\n\n### One Option: using `gridsearch()`\n\nOne way to try and optimize these hyper-parameters is to try all combinations (assuming we have discretized our parameters). Darts offers a `gridsearch()` method to do just that. The advantage is that it is very simple to use. However, it also has severe drawbacks:\n\n* It takes exponential time in the number of hyper-parameters: grid-searching over any non-trivial number of hyperparameters thus quickly becomes intractable.\n* Gridsearch is naive: it does not attempt to pay attention to regions of the hyperparameter space that are more promising than others. It is limited points in the pre-defined grid.\n* Finally, for simplicity reasons the Darts `gridsearch()` method is (at least at the time of writing) limited to working on one time series only.\n\nFor all these reasons, for any serious hyperparameter search, we need better techniques than grid-search. Fortunately, there are some great tools out there to help us.\n\n## Using Optuna\n\n[Optuna](https://optuna.org/) is a very nice open-source library for hyperparameter optimization. It's based on ideas such as Bayesian optimization, which balance exploration (of the hyperparameter space) with exploitation (namely, exploring more the parts of the space that look more promising). It can also use pruning in order to stop unpromising experiments early.\n\nIt's very easy to make it work: Optuna will take care of suggesting (sampling) hyper-parameters for us, and more or less all we need to do is to compute the objective value for a set of hyperparameters. In our case it consists in using these hyperparameters to build a model, train it, and report the obtained validation accuracy. We also setup a PyTorch Lightning pruning callback in order to early-stop unpromising experiments. All of this is done in the `objective()` function below.\n\nNow that we have specified our objective, all we need to do is create an Optuna study, and run the optimization. We can either ask Optuna to run for a specified period of time (as we do here), or a certain number of trials. Let's run the optimization for a couple of hours:\n\nNote: If we wanted to optimize further, we could still call `study.optimize()` more times to resume where we left off\n\nThere's a lot more that you can do with Optuna. We refer to [the documentation](https://optuna.readthedocs.io/en/stable/index.html) for more information. For instance, it's possible to obtain useful insights into the optimization process, by visualising the objective value history (over trials), the objective value as a function of some of the hyperparameters, or the overall importance of some of the hyperparameters. \n\n## Picking up the best model\n\nAfter running the hyperparameter optimization for a couple of hours on a GPU, we got:\n\n```\nBest value: 14.720555851487694, Best params: {'days_in': 14, 'days_out': 6, 'kernel_size': 19, 'num_filters': 19, 'weight_norm': True, 'dilation_base': 4, 'dropout': 0.07718156729165897, 'lr': 0.0008841998396117885, 'dayofweek': False}\n```\n\nWe can now take these hyperparameters and train the \"best\" model again. This time, we will directly try to fit a probabilistic model (using a Gaussian likelihood). Note that this actually changes the loss, so we're hoping that our hyperparameters are not too sensitive in that regard.\n\nLet's now look at the accuracy of stochastic forecasts, with 100 samples:\n\nThe accuracy seems really good, and this model does not suffer from some of the same issues that our initial linear regression and early TCN had (look for instance in the failure modes it used to have on series 150). \n\nLet's now also see how it performs on the test set:\n\nThe performance is not as good on the test set, but on closer inspection this seems to be due to the Christmas time, during which some of the clients (unsurprisingly) changed their consumption. Besides the Christmas time, the quality of the forecasts seems roughly on par with what we had during the validation set, which is a good indication that we probably did not overfit our hyperparameter optimization to the validation set.\n\nTo improve this model further, it might be a good idea to consider using indicator variables capturing public holidays (which we haven't done here).\n\nAs a last experiment, let's see how our linear regression model performs on the test set:\n\n## Conclusions\n\nWe have seen in this notebook that Optuna can be seamlessly used to optimize the hyper-parameters of Darts' models. In fact, there's nothing really particular to Darts when it comes to hyperparameter optimization: Optuna and other libraries can be used as they would with other frameworks. The only thing to be aware of are the PyTorch Ligthning integrations, which are available through Darts.\n\n### Side conclusion: shall we go with linear regression or TCN to forecast electricty consumption?\n\nBoth approaches have pros and cons.\n\n**Pros of linear regression:**\n\n* Simplicity\n* Does not require scaling\n* Speed\n* Does not require a GPU\n* Often provides good performance out-of-the-box, without requiring tuning\n\n**Cons of linear regression:**\n\n* Can require a significant amount of memory (when used as a global model as here), although there are ways around that (e.g., SGD-based).\n* In our setting, it's impractical to train a stochastic version of the `LinearRegression` model, as this would incur too large a computational complexity.\n\n**TCN, pros:**\n\n* Potentially more tuneable and powerful\n* Typically lower memory requirements thanks to SGD\n* Very rich support to capture stochasticity in different ways, without requiring significantly more computation\n* Very fast bulk inference over many time series once the model is trained - especially if using a GPU\n\n**TCN, cons:**\n\n* More hyperparameters, which can take longer to tune and offer more risks of overfitting. It also means that the model is harder to industrialize and maintain\n* Will often require a GPU\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":false,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"jupyter"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["styles.css"],"toc":true,"output-file":"hyperparameter optimization.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.8.27","comments":{"utterances":{"repo":"quarto-dev/quarto-web"}},"author":"Benedict Thekkel","theme":{"light":"flatly","dark":"darkly"},"description":"[In this notebook, we demonstrate how to carry out hyperparameter optimization using a deep learning forecasting model in order to accurately forecast electricity loads with confidence intervals.](https://unit8co.github.io/darts/examples/17-hyperparameter-optimization.html)","title":"Darts - Hyper-parameters Optimization for Electricity Load Forecasting"},"extensions":{"book":{"multiFile":true}}},"gfm":{"identifier":{"display-name":"Github (GFM)","target-format":"gfm","base-format":"gfm"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"png","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":false,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"jupyter"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":false,"output-ext":"md","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":true,"merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"variant":"+autolink_bare_uris+emoji+footnotes+gfm_auto_identifiers+pipe_tables+strikeout+task_lists+tex_math_dollars"},"pandoc":{"standalone":true,"default-image-extension":"png","to":"commonmark","output-file":"hyperparameter optimization.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"comments":{"utterances":{"repo":"quarto-dev/quarto-web"}},"description":"[In this notebook, we demonstrate how to carry out hyperparameter optimization using a deep learning forecasting model in order to accurately forecast electricity loads with confidence intervals.](https://unit8co.github.io/darts/examples/17-hyperparameter-optimization.html)","title":"Darts - Hyper-parameters Optimization for Electricity Load Forecasting"}}},"projectFormats":["html","gfm"]}